import sqlite3
import os
import signal
import sys
import threading
import time
from contextlib import contextmanager

# Fun√ß√£o para inicializar o banco e criar tabela se n√£o existir
def init_db():
    try:
        db_path = os.path.join(os.path.dirname(__file__), 'historico_base.db')
        conn = sqlite3.connect(db_path, timeout=10)
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS historico (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                usuario TEXT,
                prompt TEXT,
                resposta TEXT,
                data DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        conn.commit()
        conn.close()
        print("‚úÖ Banco de dados inicializado com sucesso")
    except Exception as e:
        print(f"‚ùå Erro ao inicializar banco: {e}")

# Pool de conex√µes para SQLite
@contextmanager
def get_db_connection():
    conn = None
    try:
        db_path = os.path.join(os.path.dirname(__file__), 'historico_base.db')
        conn = sqlite3.connect(db_path, timeout=10)
        yield conn
    except Exception as e:
        if conn:
            conn.rollback()
        print(f"‚ùå Erro na conex√£o com banco: {e}")
        raise
    finally:
        if conn:
            conn.close()

# Inicializar banco ao iniciar app
init_db()

from flask import Flask, request, jsonify, send_from_directory, send_file
from flask_cors import CORS
import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
app = Flask(__name__)
CORS(app)

# Configura√ß√µes de timeout
REQUEST_TIMEOUT = 120  # 2 minutos para requisi√ß√µes OpenAI
OPENAI_TIMEOUT = 90    # 1.5 minutos para OpenAI especificamente

# Middleware de monitoramento
@app.before_request
def before_request():
    request.start_time = time.time()

@app.after_request
def after_request(response):
    duration = time.time() - request.start_time
    if duration > 5:  # Log apenas requisi√ß√µes longas
        print(f"‚ö†Ô∏è Requisi√ß√£o lenta: {request.endpoint} - {duration:.2f}s")
    return response

# Middleware para limpeza de mem√≥ria
import gc

@app.teardown_appcontext  
def cleanup(exception):
    gc.collect()  # For√ßar garbage collection

# Tratamento de sinais para graceful shutdown
def signal_handler(signum, frame):
    print(f"\nüõë Recebido sinal {signum}. Finalizando aplica√ß√£o...")
    sys.exit(0)

signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)

# Rota otimizada para servir arquivos est√°ticos 
@app.route('/static/<path:filename>')
def static_files(filename):
    try:
        static_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'analise-bid-ia-tools')
        return send_from_directory(static_path, filename, as_attachment=False, cache_timeout=3600)
    except Exception as e:
        print(f"‚ùå Erro ao servir arquivo est√°tico {filename}: {e}")
        return jsonify({'error': 'Arquivo n√£o encontrado'}), 404

# Inicializar o cliente OpenAI com configura√ß√µes otimizadas
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    timeout=OPENAI_TIMEOUT,
    max_retries=2
)

# Fun√ß√£o para processar requisi√ß√£o com timeout
def process_openai_request(messages, model, max_tokens):
    """Processa requisi√ß√£o OpenAI com controle de timeout"""
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=0.7,
            timeout=OPENAI_TIMEOUT
        )
        return response, None
    except Exception as e:
        return None, str(e)

# Fun√ß√£o ass√≠ncrona para salvar hist√≥rico
def save_to_history_async(usuario, prompt, resposta):
    """Salva hist√≥rico de forma ass√≠ncrona para n√£o bloquear resposta"""
    def save_task():
        try:
            with get_db_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    'INSERT INTO historico (usuario, prompt, resposta) VALUES (?, ?, ?)',
                    (usuario, str(prompt), resposta)
                )
                conn.commit()
                print("‚úÖ Hist√≥rico salvo com sucesso")
        except Exception as e:
            print(f"‚ùå Erro ao salvar hist√≥rico: {e}")
    
    # Executar em thread separada
    thread = threading.Thread(target=save_task)
    thread.daemon = True
    thread.start()

@app.route('/api/chat', methods=['POST'])
def chat():
    start_time = time.time()
    
    try:
        data = request.json
        messages = data.get('messages', [])
        model = data.get('model', 'gpt-4')
        max_tokens = min(data.get('max_tokens', 2000), 4000)  # Limitar tokens
        
        print("üöÄ === NOVA REQUISI√á√ÉO DE AN√ÅLISE ===")
        print(f"üìß Modelo: {model}")
        print(f"üî¢ Max Tokens: {max_tokens}")
        print(f"üìù Total de mensagens: {len(messages)}")
        print("=" * 50)

        # Valida√ß√£o b√°sica
        if not messages:
            return jsonify({'error': 'Nenhuma mensagem fornecida'}), 400
        
        if len(str(messages)) > 50000:  # Limitar tamanho do prompt
            return jsonify({'error': 'Prompt muito longo. Reduza o tamanho do texto.'}), 400

        # Processar requisi√ß√£o OpenAI
        response, error = process_openai_request(messages, model, max_tokens)
        
        if error:
            print(f"‚ùå ERRO na API OpenAI: {error}")
            return jsonify({'error': f'Erro na API OpenAI: {error}'}), 500
        
        if not response or not response.choices:
            return jsonify({'error': 'Resposta vazia da OpenAI'}), 500

        content = response.choices[0].message.content
        processing_time = time.time() - start_time
        
        print("‚úÖ Resposta da OpenAI recebida com sucesso!")
        print(f"üìÑ Tamanho da resposta: {len(content)} caracteres")
        print(f"‚è±Ô∏è Tempo de processamento: {processing_time:.2f}s")
        print("=" * 50)

        # Salvar hist√≥rico de forma ass√≠ncrona
        save_to_history_async(
            data.get('usuario', 'anonimo'),
            messages,
            content
        )

        return jsonify({
            'choices': [{
                'message': {
                    'content': content
                }
            }],
            'processing_time': round(processing_time, 2)
        })
        
    except Exception as e:
        processing_time = time.time() - start_time
        error_msg = f"Erro interno do servidor: {str(e)}"
        print(f"‚ùå ERRO GERAL: {error_msg}")
        print(f"‚è±Ô∏è Tempo at√© erro: {processing_time:.2f}s")
        print("=" * 50)
        return jsonify({'error': error_msg}), 500

@app.route('/api/health', methods=['GET'])
def health():
    """Endpoint de sa√∫de com informa√ß√µes detalhadas"""
    try:
        # Testar conex√£o com banco
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM historico')
            total_records = cursor.fetchone()[0]
        
        return jsonify({
            "status": "ok",
            "openai_configured": bool(os.getenv("OPENAI_API_KEY")),
            "database_working": True,
            "total_records": total_records,
            "timeout_config": {
                "request_timeout": REQUEST_TIMEOUT,
                "openai_timeout": OPENAI_TIMEOUT
            }
        })
    except Exception as e:
        return jsonify({
            "status": "error",
            "openai_configured": bool(os.getenv("OPENAI_API_KEY")),
            "database_working": False,
            "error": str(e)
        }), 500

@app.route('/api/historico', methods=['GET'])
def get_historico():
    """Endpoint otimizado para buscar hist√≥rico"""
    try:
        limit = request.args.get('limit', 50, type=int)
        offset = request.args.get('offset', 0, type=int)
        
        # Limitar resultados para evitar sobrecarga
        limit = min(limit, 100)
        
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(
                'SELECT id, usuario, prompt, resposta, data FROM historico ORDER BY data DESC LIMIT ? OFFSET ?',
                (limit, offset)
            )
            rows = cursor.fetchall()
            
            # Contar total de registros
            cursor.execute('SELECT COUNT(*) FROM historico')
            total = cursor.fetchone()[0]
        
        historico = [
            {
                'id': row[0],
                'usuario': row[1],
                'prompt': row[2][:500] + '...' if len(row[2]) > 500 else row[2],  # Truncar prompt longo
                'resposta': row[3][:1000] + '...' if len(row[3]) > 1000 else row[3],  # Truncar resposta longa
                'data': row[4]
            }
            for row in rows
        ]
        
        return jsonify({
            'historico': historico,
            'total': total,
            'limit': limit,
            'offset': offset
        })
    except Exception as e:
        print(f"‚ùå Erro ao buscar hist√≥rico: {e}")
        return jsonify({'error': str(e)}), 500

# Rota otimizada para servir arquivos da pasta App-IA
@app.route('/App-IA/<path:filename>')
def serve_app_ia_files(filename):
    try:
        app_ia_path = os.path.join(os.path.dirname(os.path.dirname(__file__)))
        return send_from_directory(app_ia_path, filename, as_attachment=False, cache_timeout=3600)
    except Exception as e:
        print(f"‚ùå Erro ao servir arquivo App-IA {filename}: {e}")
        return jsonify({'error': 'Arquivo n√£o encontrado'}), 404

# Rota otimizada para a p√°gina principal
@app.route('/')
def index():
    try:
        app_ia_path = os.path.dirname(os.path.dirname(__file__))
        return send_file(os.path.join(app_ia_path, 'document_ai_app.html'))
    except Exception as e:
        print(f"‚ùå Erro ao servir p√°gina principal: {e}")
        return jsonify({'error': 'P√°gina n√£o encontrada'}), 404

if __name__ == '__main__':
    print("=" * 70)
    print("üöÄ TOOLS ENGENHARIA - DOCUMENT AI ANALYZER BACKEND")
    print("=" * 70)
    print("üåê Servidor Flask iniciado em: http://localhost:5000")
    print("ü§ñ OpenAI API: Configurada e pronta")
    print("üìä Endpoints dispon√≠veis:")
    print("   ‚Ä¢ POST /api/chat - An√°lise de documentos")
    print("   ‚Ä¢ GET  /api/health - Status do sistema")
    print("   ‚Ä¢ GET  /api/historico - Hist√≥rico de an√°lises")
    print("   ‚Ä¢ GET  / - Interface principal")
    print("=" * 70)
    print("üí° Logs da aplica√ß√£o aparecer√£o abaixo:")
    print("=" * 70)
    
    # Para desenvolvimento local
    app.run(debug=False, port=5000, threaded=True)

# Para produ√ß√£o (Render/Vercel)
app = app